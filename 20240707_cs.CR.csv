,id,title,authors,published,summary,generated_summary
0,2407.05237v1,"Privacy of the last iterate in cyclically-sampled DP-SGD on nonconvex
  composite losses",Weiwei Kong; Mónica Ribero,2024-07-07 02:35:55,"Differentially private stochastic gradient descent (DP-SGD) refers to a family of optimization algorithms that provide a guaranteed level of differential privacy (DP) through DP accounting techniques. However, current accounting techniques make assumptions that diverge significantly from practical DP-SGD implementations. For example, they may assume the loss function is Lipschitz continuous and convex, sample the batches randomly with replacement, or omit the gradient clipping step.   In this work, we analyze the most commonly used variant of DP-SGD, in which we sample batches cyclically with replacement, perform gradient clipping, and only release the last DP-SGD iterate. More specifically - without assuming convexity, smoothness, or Lipschitz continuity of the loss function - we establish new R\'enyi differential privacy (RDP) bounds for the last DP-SGD iterate under the mild assumption that (i) the DP-SGD stepsize is small relative to the topological constants in the loss function, and (ii) the loss function is weakly-convex. Moreover, we show that our bounds converge to previously established convex bounds when the weak-convexity parameter of the objective function approaches zero. In the case of non-Lipschitz smooth loss functions, we provide a weaker bound that scales well in terms of the number of DP-SGD iterations.","以下是文章的摘要：

本文研究了加噁私密随机梯度下降算法（DP-SGD）中账户技术的实际实施方法。该算法认为损失函数 Lipschitz 连续和凸，但实际情况中这些假设不成立。文章中建立了一些新的R\'enyi diferencia	privacy（RDP）界限，这些界限不需要损失函数的凸性、 smoothness和Lipschitz 连续性，只需要损失函数弱凸和 DP-SGD步长相对小。这些界限在弱凸参数趋近于零时会收敛到之前建立的凸界限。"
1,2407.05285v1,Gradient Diffusion: A Perturbation-Resilient Gradient Leakage Attack,Xuan Liu; Siqi Cai; Qihua Zhou; Song Guo; Ruibin Li; Kaiwei Lin,2024-07-07 07:06:49,"Recent years have witnessed the vulnerability of Federated Learning (FL) against gradient leakage attacks, where the private training data can be recovered from the exchanged gradients, making gradient protection a critical issue for the FL training process. Existing solutions often resort to perturbation-based mechanisms, such as differential privacy, where each participating client injects a specific amount of noise into local gradients before aggregating to the server, and the global distribution variation finally conceals the gradient privacy. However, perturbation is not always the panacea for gradient protection since the robustness heavily relies on the injected noise. This intuition raises an interesting question: \textit{is it possible to deactivate existing protection mechanisms by removing the perturbation inside the gradients?} In this paper, we present the answer: \textit{yes} and propose the Perturbation-resilient Gradient Leakage Attack (PGLA), the first attempt to recover the perturbed gradients, without additional access to the original model structure or third-party data. Specifically, we leverage the inherent diffusion property of gradient perturbation protection and construct a novel diffusion-based denoising model to implement PGLA. Our insight is that capturing the disturbance level of perturbation during the diffusion reverse process can release the gradient denoising capability, which promotes the diffusion model to generate approximate gradients as the original clean version through adaptive sampling steps. Extensive experiments demonstrate that PGLA effectively recovers the protected gradients and exposes the FL training process to the threat of gradient leakage, achieving the best quality in gradient denoising and data recovery compared to existing models. We hope to arouse public attention on PGLA and its defense.","Here is a summary of the article in Chinese:

最近几年来，Federated Learning (FL)对抗梯度泄露攻击的脆弱性表明，保护梯度隐私对于 FL训练过程的重要性。现有的解决方案通常通过lod不同量的噪声 Noise 到本地梯度中，并在服务器上聚合，以最终将梯度隐私混淆。然而，噪声jection并不总是保护梯度隐私的万能法 вспа some intuition raises a question: 是不能通过去除噪声就将现有的保护机制关闭？本文回答说是，提出了Perturbation-resilient Gradient Leakage Attack（PGLA），这是首次恢复意ention Perturbed 梯度，而无需额外访问原始模型结构或第三方数据。我们leveraged 梯度保护噪声的内在扩散性质，构建了一个 novel_diffusion-based_denoising_model_l来实现 PGLA。我们的-insight是，如果在扩散反向过程中捕捉扰动噪声的level，可以通过 adaptive_denoising_steps使扩散模型生成与原始清洁版本とする某定的梯度 denoising capability，促进扩散模型生成的梯度Approx为原始清洁版本。实验结果表明，PGLA能够有效恢复保护了的梯度， expose 了 FL 训练过程对梯度泄露的威胁，使其获得了现有模型中的最佳idenosing 和数据恢复质量。我们希望通过 PGLA evacue公众的关注和防御。"
2,2407.05290v1,Lack of Systematic Approach to Security of IoT Context Sharing Platforms,Mohammad Goudarzi; Arash Shaghaghi; Simon Finn; Sanjay Jha,2024-07-07 07:11:15,IoT context-sharing platforms are an essential component of today's interconnected IoT deployments with their security affecting the entire deployment and the critical infrastructure adopting IoT. We report on a lack of systematic approach to the security of IoT context-sharing platforms and propose the need for a methodological and systematic alternative to evaluate the existing solutions and develop `secure-by-design' solutions. We have identified the key components of a generic IoT context-sharing platform and propose using MITRE ATT&CK for threat modelling of such platforms.,"以下是文章摘要的中文总结：

文章论述了IoT上下文共享平台对整个分布式IoT部署和关键基础设施的影响，同时指出缺乏系统的IoT上下文共享平台安全评估方法，提出了ereal-time-by-design解决方案。作者提出了IoT上下文共享平台的关键组件，并建议使用MITRE ATT&CK进行威胁建模。"
3,2407.05318v1,"Vulnerability-Hunter: An Adaptive Feature Perception Attention Network
  for Smart Contract Vulnerabilities",Yizhou Chen,2024-07-07 10:13:41,"Smart Contract Vulnerability Detection (SCVD) is crucial to guarantee the quality of blockchain-based systems. Graph neural networks have been shown to be effective in learning semantic representations of smart contract code and are commonly adopted by existing deep learning-based SCVD. However, the current methods still have limitations in their utilization of graph sampling or subgraph pooling based on predefined rules for extracting crucial components from structure graphs of smart contract code. These predefined rule-based strategies, typically designed using static rules or heuristics, demonstrate limited adaptability to dynamically adjust extraction strategies according to the structure and content of the graph in heterogeneous topologies of smart contract code. Consequently, these strategies may not possess universal applicability to all smart contracts, potentially leading to false positives or omissions. To address these problems, we propose AFPNet, a novel vulnerability detection model equipped with a feature perception module that has dynamic weights for comprehensive scanning of the entire smart contract code and automatic extraction of crucial code snippets (the $P$ snippets with the largest weights). Subsequently, the relationship perception attention module employs an attention mechanism to learn dependencies among these code snippets and detect smart contract vulnerabilities. The efforts made by AFPNet consistently enable the capture of crucial code snippets and enhance the performance of SCVD optimization. We conduct an evaluation of AFPNet in the several large-scale datasets with vulnerability labels. The experimental results show that our AFPNet significantly outperforms the state-of-the-art approach by 6.38\%-14.02\% in term of F1-score. The results demonstrate the effectiveness of AFPNet in dynamically extracting valuable information and vulnerability detection.","本文总结：

智能合约漏洞检测（Smart Contract Vulnerability Detection，SCVD）在区块链系统中的 Qualitätassurance 是非常重要的任务。当前的深度学习基于的SCVD方法主要使用图神经网络（Graph Neural Networks），但是這些方法仍然存在利用图采样或子图池的缺陷。为了解决这些问题，本文提出了AFPNet模型，该模型具有动态权重的特征识别模块和关系识别注意模块。在AFPNet模型中，我们可以自动地提取关键代码片段，并且可以学习这些代码片段之间的依赖关系从而检测智能合约漏洞。实验结果表明，AFPNet在多个大规模数据集上 {}:互联网($""F1-score"")上显著超越当前的 state-of-the-art 方法（6.38%~14.02%），证明了AFPNet在智能合约漏洞检测中的有效性。"
4,2407.05396v1,"Evolutionary Trigger Detection and Lightweight Model Repair Based
  Backdoor Defense",Qi Zhou; Zipeng Ye; Yubo Tang; Wenjian Luo; Yuhui Shi; Yan Jia,2024-07-07 14:50:59,"Deep Neural Networks (DNNs) have been widely used in many areas such as autonomous driving and face recognition. However, DNN model is fragile to backdoor attack. A backdoor in the DNN model can be activated by a poisoned input with trigger and leads to wrong prediction, which causes serious security issues in applications. It is challenging for current defenses to eliminate the backdoor effectively with limited computing resources, especially when the sizes and numbers of the triggers are variable as in the physical world. We propose an efficient backdoor defense based on evolutionary trigger detection and lightweight model repair. In the first phase of our method, CAM-focus Evolutionary Trigger Filter (CETF) is proposed for trigger detection. CETF is an effective sample-preprocessing based method with the evolutionary algorithm, and our experimental results show that CETF not only distinguishes the images with triggers accurately from the clean images, but also can be widely used in practice for its simplicity and stability in different backdoor attack situations. In the second phase of our method, we leverage several lightweight unlearning methods with the trigger detected by CETF for model repair, which also constructively demonstrate the underlying correlation of the backdoor with Batch Normalization layers. Source code will be published after accepted.","以下是文章的摘要：

深度神经网络（DNN）在自动驾驶、人脸识别等领域中取得了广泛应用。但是,DNN模型对背doors攻击非常脆弱。背doors攻击可以通过带有触发器的 poisoned 数据输入来激活模型，从而导致错误预测，导致严重的安全问题。当前防御手段对背doors攻击的防御效果有限，尤其是在触发器的大小和数量不定时。文章 proposes 了一种高效的背doors防御方法，基于进化Trigger检测和轻量级模型修复。该方法由两个阶段组成：首先使用CAM-focus Evolutionary Trigger Filter（CETF）对触发器进行检测；其次使用轻量级unlearning方法对模型进行修复，并探索背doors攻击与Batch Normalization层之间的联系。"
5,2407.05446v1,"Towards Perceived Security, Perceived Privacy, and the Universal Design
  of E-Payment Applications",Urvashi Kishnani; Isabella Cardenas; Jailene Castillo; Rosalyn Conry; Lukas Rodwin; Rika Ruiz; Matthew Walther; Sanchari Das,2024-07-07 17:15:09,"With the growth of digital monetary transactions and cashless payments, encouraged by the COVID-19 pandemic, use of e-payment applications is on the rise. It is thus imperative to understand and evaluate the current posture of e-payment applications from three major user-facing angles: security, privacy, and usability. To this, we created a high-fidelity prototype of an e-payment application that encompassed features that we wanted to test with users. We then conducted a pilot study where we recruited 12 participants who tested our prototype. We find that both security and privacy are important for users of e-payment applications. Additionally, some participants perceive the strength of security and privacy based on the usability of the application. We provide recommendations such as universal design of e-payment applications.","本文总结：

随着数字货币交易和无现金支付的增长， due to the COVID-19 pandemic，电汇应用程序的使用正在不断增长。因此，了解和评估电汇应用程序的当前状态是必要的，分为安全、隐私和可用性三个主要用户面向。作者通过创建了一个高保真度的电汇应用程序原型，测试了12名参与者的反应。研究发现，无论是安全还是隐私，对电汇应用程序的用户都是非常重要的。同时，某些参与者认为，基于应用程序的可用性来评估安全和隐私的强度。作者提出了建议，如电汇应用程序的universal design。"
